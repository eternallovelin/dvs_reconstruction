We use Kalman Filters to reconstruct the grayscale image from the noisy DVS signal. For each pixel in the output image there is a Kalman Filter that keeps track of the color gradient at the pixel position. The input to the Kalman Filter is the event frequency on a line along the current pixel movement. Hereby it is assumed that the pixel's movement was constant since the last event it triggered. While this is obviously not true all the time, it is a good approximation due to the high rate of events. Note that the pixel movement is not necessarily parallel to the camera movement, e.g. if the camera is rotating around its z-axis.
The pixel movement is computed with the same formulas as used in the simulationand the map lookup during tracking. Given a camera orientation, the orientation of the ray through the pixel and the camera's focal point is computed. This is then mapped to a pixel in the output image. While we use the exact position in the output image to compute the pixel movement,  we do not, however, interpolate between several pixels when writing the signal to the map, but simply round the position in the output image th the closest pixel. Since we do not write the signal directly but use Kalman Filters to reduce the noise, this simplification greatly reduces the complexity of the algorithm compared to dividing the signals between several filters.
The exact formulas used for the Kalman Filters can be seen in \cite{kim2014simultaneous}.
In the current state of our program, we assume that the camera's initial field of view is already known and included in the map. With this assumption we do not have to deal with a special initialization procedure but can immediately start with the standard iteration while being relatively sure that the camera movement is tracked correctly.
