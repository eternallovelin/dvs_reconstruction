In order to integrate intensity change events into a full gradient map of the
environment, we must track the current position and movement direction of the
camera.
The camera's position is represented using a particle filter, where each
particle consists only of a weight and the three Euler angles necessary to
describe the camera's orientation.

Whenever a new event is received, we disturb the particles randomly with
variance proportional to the time since the last event. This is essentially a
constant position model, where the camera is assumed to stay stationary between
events but with uncertainty growing over time.

To update the weights of the disturbed particles, we retrieve the position of
the camera at the time of the last event of the \textit{same} pixel (which can be a
lot earlier than the previous event). We then sample our map (which we get from the
reconstruction part and which we assume is essentially correct) at this earlier
position. This intensity is then compared with the intensities at all the
proposed current positions: The closer the intensity difference to the
intensity threshold that generates an event, the likelier is the new position
and the more weight this particle gets.

Finally, the particles are resampled whenever the effective number of particles
(one over sum of squared weights, see \cite{kim2014simultaneous} for details)
falls below some threshold (usually $N/2$ as in \cite{kim2014simultaneous}).
Resampling is done by copying particles with probability equal to their weight
into a new set.

\subsubsection{On the Matter of Prior Positions and Accuracy}

A particle filter is a nice way of keeping track of multiple hypotheses as
might conceivably occur when updating on a single event: An event might match
multiple edges and we might only be able to resolve the correct position after
receiving further events.

But as described above, we need to know the position at the time of the
previous event of the same pixel. And as the pixels are independent, we would
have to keep a full copy of the particle filter for every pixel. This not only
requires a lot of memory, it also considerably slows down measurement updates
as we now have to compare each of the current particles with all possible
previous ones.

However, our experiments show that it is actually enough to only keep the
weighted average over the particles as any errors are quickly averaged out by
the sheer number of events. Furthermore, image gradients often cover bigger
areas than just a few pixels, which further diminishes the effect of small
errors in location.
